# django-azure-auth-ms-fabric
Running Spark using Apache Livy/Microsoft Fabric Livy endpoint. Based on Django authentication and using django-azure-auth

## Requirements
- Create an EntraID application and apply the following settings
    - On the **Manage/Authentication section**
        - Add a redirect URL in the **Web** section: http://localhost:5000/azure_auth/callback (use another endpoint for other environments)
    - On the **Certificates & secrets** section
        - Create a **client secret** and store the value in the .env file (CLIENT_SECRET)
    - On the **Token configuration** section
        - Add Optional Claim
            - Token type: ID
            - Claim: upn
        - Add Group Claim (ID, Access, SAML)
            - Group ID
            - Enable: Emit groups as role claims
    - On the **API permissions** section
        - Add permission (with grant admin consent) for
            - **Microsoft Graph** (email, GroupMember.Read.All, profile, User.Read, User.ReadBasic.All)
            - **Power BI Service** (Code.AccessAzureDataExplorer.All, Code.AccessAzureDataLake.All, Code.AccessAzureKeyvault.All, Code.AccessFabric.All, Code.AccessStorage.All, Item.ReadWrite.All, Lakehouse.Execute.All, Workspace.ReadWrite.All)
- Adjust .env file for other values
    - **DJANGO_SECRET** = Random value generated by Django framework when starting a project
    - **TENANT_ID** = Your Azure tenant ID
    - **CLIENT_ID** = Your EntraID application Client ID
    - **CLIENT_SECRET** = Your EntraID application secret
    - **REDIRECT_URI** = "http://localhost:5000/azure_auth/callback" for local testing. Use another endpoint for other environments
    - **LOGOUT_URI** = "http://localhost:5000/logout" for local testing. Use another endpoint for other environments
    - **ROLES** = '{"My_Admin_Entra_Group_ObjectID": "Administrators", "My_Editors_Entra_Group_ObjectID": "Editors", "My_Viewers_Entra_Group_ObjectID": "Viewers"}' This will map the groups you defined on EntraID side with the groups you create in Django admin
    - **GRAPH_USER_ENDPOINT** = "https://graph.microsoft.com/v1.0/me"
    - **GRAPH_MEMBER_ENDPOINT** = "https://graph.microsoft.com/v1.0/me/memberOf"
    - **LIVY_BACKEND**: Possible values "apache" or "fabric"
    - **LIVY_BASE_ENDPOINT** = "https://api.fabric.microsoft.com/v1/workspaces/MyWorkSpaceID/lakehouses/MyLakeHouseID/livyapi/versions/2023-12-01". Replace MyWorkSpaceID and MyLakeHouseID with the right values. You can also use an Apache Livy endpoint, fo example for local tests: http://localhost:8998
    - **LIVY_REQUESTS_TIMEOUT**: The timeout in seconds for the Livy REST API requests
    - **LIVY_SESSION_NAME_PREFIX**: A prefix to use for session names. Example: MyApp-. A datetime will be appended to this prefix name
    - **LIVY_SPARK_CONF**: Optional custom Spark Configuration.
    For Microsoft Fabric only, an environmentID can be enabled using the Spark configuration ```'{"spark.fabric.environmentDetails" : "{\"id\": \"My_EnvironmentID\"}"}'```. You can get the environment ID from your Fabric workspace using the REST API: https://learn.microsoft.com/en-us/rest/api/fabric/environment/items/list-environments?tabs=HTTP. If no Environment_ID is specified, the session will default to the workspace's default environment on the default pool. For faster startup experience, sessions can use the Starter Pool, a medium-sized and prehydrated live pool that is automatically created for each workspace. More information for Starter Pools can be found here: https://learn.microsoft.com/en-us/fabric/data-engineering/configure-starter-pools
    - **LIVY_SPARK_DEPENDENCIES**: Optional, a comma separated absolute paths to the Python packages to be used in the Spark session. For example: *"abfss://...path-to.../Files/packages/mypackage-0.1.0-py3-none-any.whl"*
- Create groups on Django admin
    - Disable *AUTHENTICATION_BACKENDS = ("azure_auth.backends.AzureBackend",)* on the *settings.py** file
    - Create an admin account using ```python manage.py createsuperuser```
    - Apply migration ```python manage.py migrate``` and start the Django myapp ```python manage.py runserver localhost:5000```
    - Login using admin account from http://localhost:5000/admin
    - Create groups: Administrators, Editors, Viewers
    - Assign privileges to the groups
    - Enable back *AUTHENTICATION_BACKENDS = ("azure_auth.backends.AzureBackend",)* on the **settings.py** file, and restart the Django myapp

## Setup
Create a virtual environment and run:
```
pip install -r requirements.txt
```

## How to
**Already done, don't run**
```
django-admin startproject myapp
```

**Start the Django myapp**
```
cd myapp
python manage.py migrate
python manage.py runserver localhost:5000
```

## Important
- You need to manage the Fabric token expiration as well as the Livy session timeout (ttl, see Apache Livy reference bellow)
- If using Apache Livy 0.8, consider running some java_import before running any Spark code. See: [https://github.com/mounirbs/spark-livy/blob/main/python/livy/init_java_gateway.py#L11](https://github.com/mounirbs/spark-livy/blob/main/python/livy/init_java_gateway.py#L11) 
- Both ttl and idleTimeout seems not working properly in Fabric/Apache Livy. For Apache Livy, the binaries from https://livy.apache.org/download/ where used. Maybe the binaries are not reflecting the code on the Apache Livy master branch: [https://livy.incubator.apache.org/docs/latest/rest-api.html](https://github.com/apache/incubator-livy/blob/master/docs/rest-api.md). Without using these parameters, the session does not timeout.
- The code is not production ready, since it's not handling fully all the required exceptions. This is only a proof-of-concept!
- Installing packages in Fabric:
    - From the environment running all the sessions (can be managed on Fabric side).
    - From the session: using the LIVY_SPARK_DEPENDENCIES environment variable, a list of comma separated absolute paths to the Python packages to be used in the Spark session.    

## Reference
- [https://learn.microsoft.com/en-us/fabric/data-engineering/get-started-api-livy-session](https://learn.microsoft.com/en-us/fabric/data-engineering/get-started-api-livy-session)
- [https://github.com/apache/incubator-livy/blob/master/docs/rest-api.md](https://github.com/apache/incubator-livy/blob/master/docs/rest-api.md)
- [https://livy.incubator.apache.org/docs/latest/rest-api.html](https://livy.incubator.apache.org/docs/latest/rest-api.html) (not up to date, idleTimeout is not there)
